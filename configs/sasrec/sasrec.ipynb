{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60e6c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:29:24.340284Z",
     "iopub.status.busy": "2023-11-18T08:29:24.339878Z",
     "iopub.status.idle": "2023-11-18T08:29:27.165801Z",
     "shell.execute_reply": "2023-11-18T08:29:27.164671Z"
    },
    "papermill": {
     "duration": 2.833363,
     "end_time": "2023-11-18T08:29:27.168030",
     "exception": false,
     "start_time": "2023-11-18T08:29:24.334667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Session-Based-Models'...\r\n",
      "remote: Enumerating objects: 705, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (131/131), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (119/119), done.\u001b[K\r\n",
      "remote: Total 705 (delta 87), reused 15 (delta 12), pack-reused 574\u001b[K\r\n",
      "Receiving objects: 100% (705/705), 13.05 MiB | 16.68 MiB/s, done.\r\n",
      "Resolving deltas: 100% (323/323), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/UwU-tao/Session-Based-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebfb94c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:29:27.177706Z",
     "iopub.status.busy": "2023-11-18T08:29:27.177349Z",
     "iopub.status.idle": "2023-11-18T08:29:27.184094Z",
     "shell.execute_reply": "2023-11-18T08:29:27.183086Z"
    },
    "papermill": {
     "duration": 0.013679,
     "end_time": "2023-11-18T08:29:27.185948",
     "exception": false,
     "start_time": "2023-11-18T08:29:27.172269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Session-Based-Models\n"
     ]
    }
   ],
   "source": [
    "%cd Session-Based-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a20a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:29:27.194606Z",
     "iopub.status.busy": "2023-11-18T08:29:27.194310Z",
     "iopub.status.idle": "2023-11-18T08:31:20.481389Z",
     "shell.execute_reply": "2023-11-18T08:31:20.480118Z"
    },
    "papermill": {
     "duration": 113.294285,
     "end_time": "2023-11-18T08:31:20.483996",
     "exception": false,
     "start_time": "2023-11-18T08:29:27.189711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f733b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:31:20.493639Z",
     "iopub.status.busy": "2023-11-18T08:31:20.493301Z",
     "iopub.status.idle": "2023-11-18T08:31:22.397437Z",
     "shell.execute_reply": "2023-11-18T08:31:22.396185Z"
    },
    "papermill": {
     "duration": 1.911578,
     "end_time": "2023-11-18T08:31:22.399879",
     "exception": false,
     "start_time": "2023-11-18T08:31:20.488301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "!mkdir datasets/yoochoose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92223eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:31:22.409582Z",
     "iopub.status.busy": "2023-11-18T08:31:22.409247Z",
     "iopub.status.idle": "2023-11-18T08:31:35.033600Z",
     "shell.execute_reply": "2023-11-18T08:31:35.032585Z"
    },
    "papermill": {
     "duration": 12.632089,
     "end_time": "2023-11-18T08:31:35.036096",
     "exception": false,
     "start_time": "2023-11-18T08:31:22.404007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open ('/kaggle/input/src15-clicks/rsc15-clicks.dat', 'r') as f:\n",
    "    con = f.read()\n",
    "with open('./datasets/yoochoose/yoochoose-clicks.dat', 'w') as f:\n",
    "    f.write(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdcdeb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:31:35.045444Z",
     "iopub.status.busy": "2023-11-18T08:31:35.045136Z",
     "iopub.status.idle": "2023-11-18T08:47:20.937615Z",
     "shell.execute_reply": "2023-11-18T08:47:20.936344Z"
    },
    "papermill": {
     "duration": 945.899833,
     "end_time": "2023-11-18T08:47:20.940109",
     "exception": false,
     "start_time": "2023-11-18T08:31:35.040276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 33003944/33003944 [10:30<00:00, 52379.61it/s]\r\n",
      "100%|████████████████████████████| 9249729/9249729 [00:04<00:00, 2077807.49it/s]\r\n",
      "100%|█████████████████████████████| 7990018/7990018 [00:22<00:00, 358809.42it/s]\r\n",
      "100%|████████████████████████████| 7990018/7990018 [00:04<00:00, 1976293.86it/s]\r\n",
      "100%|█████████████████████████████████| 15324/15324 [00:00<00:00, 961861.58it/s]\r\n",
      "100%|██████████████████████████| 31637239/31637239 [00:12<00:00, 2519546.09it/s]\r\n",
      "100%|█████████████████████████████| 7966257/7966257 [00:16<00:00, 469283.45it/s]\r\n",
      "100%|█████████████████████████████████| 15324/15324 [00:00<00:00, 295247.06it/s]\r\n",
      "100%|██████████████████████████████| 7966257/7966257 [02:11<00:00, 60360.42it/s]\r\n",
      "100%|██████████████████████████████████| 15324/15324 [00:00<00:00, 56075.21it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python src/preprocessing.py --dataset yoochoose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492844c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:47:22.274170Z",
     "iopub.status.busy": "2023-11-18T08:47:22.273778Z",
     "iopub.status.idle": "2023-11-18T09:15:29.877036Z",
     "shell.execute_reply": "2023-11-18T09:15:29.876080Z"
    },
    "papermill": {
     "duration": 1688.276622,
     "end_time": "2023-11-18T09:15:29.879340",
     "exception": false,
     "start_time": "2023-11-18T08:47:21.602718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\r\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:211: You called `self.log('test_seq_len', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\r\n",
      "Epoch 0: 100%|███████████████████| 62236/62236 [27:08<00:00, 38.21it/s, v_num=0]\r\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\r\n",
      "Validation:   0%|                                       | 0/119 [00:00<?, ?it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   0%|                          | 0/119 [00:00<?, ?it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   1%|▏                 | 1/119 [00:00<00:10, 10.98it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   2%|▎                 | 2/119 [00:00<00:09, 12.71it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   3%|▍                 | 3/119 [00:00<00:08, 13.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   3%|▌                 | 4/119 [00:00<00:08, 14.30it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   4%|▊                 | 5/119 [00:00<00:07, 14.54it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   5%|▉                 | 6/119 [00:00<00:07, 14.67it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   6%|█                 | 7/119 [00:00<00:07, 14.75it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   7%|█▏                | 8/119 [00:00<00:07, 14.98it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   8%|█▎                | 9/119 [00:00<00:07, 15.14it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   8%|█▍               | 10/119 [00:00<00:07, 15.21it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   9%|█▌               | 11/119 [00:00<00:07, 15.25it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  10%|█▋               | 12/119 [00:00<00:06, 15.37it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  11%|█▊               | 13/119 [00:00<00:06, 15.46it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  12%|██               | 14/119 [00:00<00:06, 15.52it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  13%|██▏              | 15/119 [00:00<00:06, 15.57it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  13%|██▎              | 16/119 [00:01<00:06, 15.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  14%|██▍              | 17/119 [00:01<00:06, 15.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  15%|██▌              | 18/119 [00:01<00:06, 15.72it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  16%|██▋              | 19/119 [00:01<00:06, 15.78it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  17%|██▊              | 20/119 [00:01<00:06, 15.84it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  18%|███              | 21/119 [00:01<00:06, 15.89it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  18%|███▏             | 22/119 [00:01<00:06, 15.94it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  19%|███▎             | 23/119 [00:01<00:06, 15.98it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  20%|███▍             | 24/119 [00:01<00:05, 15.97it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  21%|███▌             | 25/119 [00:01<00:05, 15.98it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  22%|███▋             | 26/119 [00:01<00:05, 16.02it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  23%|███▊             | 27/119 [00:01<00:05, 16.05it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  24%|████             | 28/119 [00:01<00:05, 16.07it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  24%|████▏            | 29/119 [00:01<00:05, 16.09it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  25%|████▎            | 30/119 [00:01<00:05, 16.10it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  26%|████▍            | 31/119 [00:01<00:05, 16.08it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  27%|████▌            | 32/119 [00:01<00:05, 16.09it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  28%|████▋            | 33/119 [00:02<00:05, 16.10it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  29%|████▊            | 34/119 [00:02<00:05, 16.12it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  29%|█████            | 35/119 [00:02<00:05, 16.13it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  30%|█████▏           | 36/119 [00:02<00:05, 16.15it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  31%|█████▎           | 37/119 [00:02<00:05, 16.17it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  32%|█████▍           | 38/119 [00:02<00:05, 16.16it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  33%|█████▌           | 39/119 [00:02<00:04, 16.17it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  34%|█████▋           | 40/119 [00:02<00:04, 16.18it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  34%|█████▊           | 41/119 [00:02<00:04, 16.20it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  35%|██████           | 42/119 [00:02<00:04, 16.22it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  36%|██████▏          | 43/119 [00:02<00:04, 16.24it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  37%|██████▎          | 44/119 [00:02<00:04, 16.25it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  38%|██████▍          | 45/119 [00:02<00:04, 16.25it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  39%|██████▌          | 46/119 [00:02<00:04, 16.28it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  39%|██████▋          | 47/119 [00:02<00:04, 16.29it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  40%|██████▊          | 48/119 [00:02<00:04, 16.30it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  41%|███████          | 49/119 [00:03<00:04, 16.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  42%|███████▏         | 50/119 [00:03<00:04, 16.32it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  43%|███████▎         | 51/119 [00:03<00:04, 16.33it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  44%|███████▍         | 52/119 [00:03<00:04, 16.34it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  45%|███████▌         | 53/119 [00:03<00:04, 16.33it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  45%|███████▋         | 54/119 [00:03<00:03, 16.36it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  46%|███████▊         | 55/119 [00:03<00:03, 16.36it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  47%|████████         | 56/119 [00:03<00:03, 16.38it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  48%|████████▏        | 57/119 [00:03<00:03, 16.38it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  49%|████████▎        | 58/119 [00:03<00:03, 16.40it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  50%|████████▍        | 59/119 [00:03<00:03, 16.41it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  50%|████████▌        | 60/119 [00:03<00:03, 16.40it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  51%|████████▋        | 61/119 [00:03<00:03, 16.37it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  52%|████████▊        | 62/119 [00:03<00:03, 16.30it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  53%|█████████        | 63/119 [00:03<00:03, 16.29it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  54%|█████████▏       | 64/119 [00:03<00:03, 16.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  55%|█████████▎       | 65/119 [00:03<00:03, 16.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  55%|█████████▍       | 66/119 [00:04<00:03, 16.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  56%|█████████▌       | 67/119 [00:04<00:03, 16.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  57%|█████████▋       | 68/119 [00:04<00:03, 16.30it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  58%|█████████▊       | 69/119 [00:04<00:03, 16.28it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  59%|██████████       | 70/119 [00:04<00:03, 16.29it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  60%|██████████▏      | 71/119 [00:04<00:02, 16.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  61%|██████████▎      | 72/119 [00:04<00:02, 16.33it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  61%|██████████▍      | 73/119 [00:04<00:02, 16.36it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  62%|██████████▌      | 74/119 [00:04<00:02, 16.38it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  63%|██████████▋      | 75/119 [00:04<00:02, 16.40it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  64%|██████████▊      | 76/119 [00:04<00:02, 16.42it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  65%|███████████      | 77/119 [00:04<00:02, 16.44it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  66%|███████████▏     | 78/119 [00:04<00:02, 16.46it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  66%|███████████▎     | 79/119 [00:04<00:02, 16.48it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  67%|███████████▍     | 80/119 [00:04<00:02, 16.49it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  68%|███████████▌     | 81/119 [00:04<00:02, 16.49it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  69%|███████████▋     | 82/119 [00:04<00:02, 16.51it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  70%|███████████▊     | 83/119 [00:05<00:02, 16.52it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  71%|████████████     | 84/119 [00:05<00:02, 16.53it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  71%|████████████▏    | 85/119 [00:05<00:02, 16.55it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  72%|████████████▎    | 86/119 [00:05<00:01, 16.57it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  73%|████████████▍    | 87/119 [00:05<00:01, 16.58it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  74%|████████████▌    | 88/119 [00:05<00:01, 16.60it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  75%|████████████▋    | 89/119 [00:05<00:01, 16.60it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  76%|████████████▊    | 90/119 [00:05<00:01, 16.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  76%|█████████████    | 91/119 [00:05<00:01, 16.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  77%|█████████████▏   | 92/119 [00:05<00:01, 16.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 93/119 [00:05<00:01, 16.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  79%|█████████████▍   | 94/119 [00:05<00:01, 16.67it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  80%|█████████████▌   | 95/119 [00:05<00:01, 16.67it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  81%|█████████████▋   | 96/119 [00:05<00:01, 16.68it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  82%|█████████████▊   | 97/119 [00:05<00:01, 16.69it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  82%|██████████████   | 98/119 [00:05<00:01, 16.70it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  83%|██████████████▏  | 99/119 [00:05<00:01, 16.71it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 100/119 [00:05<00:01, 16.73it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 101/119 [00:06<00:01, 16.75it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  86%|█████████████▋  | 102/119 [00:06<00:01, 16.77it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  87%|█████████████▊  | 103/119 [00:06<00:00, 16.78it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 104/119 [00:06<00:00, 16.80it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  88%|██████████████  | 105/119 [00:06<00:00, 16.81it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 106/119 [00:06<00:00, 16.83it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 107/119 [00:06<00:00, 16.84it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 108/119 [00:06<00:00, 16.86it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 109/119 [00:06<00:00, 16.87it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 110/119 [00:06<00:00, 16.89it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 111/119 [00:06<00:00, 16.90it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  94%|███████████████ | 112/119 [00:06<00:00, 16.92it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  95%|███████████████▏| 113/119 [00:06<00:00, 16.94it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  96%|███████████████▎| 114/119 [00:06<00:00, 16.96it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  97%|███████████████▍| 115/119 [00:06<00:00, 16.99it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  97%|███████████████▌| 116/119 [00:06<00:00, 17.01it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  98%|███████████████▋| 117/119 [00:06<00:00, 17.02it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  99%|███████████████▊| 118/119 [00:06<00:00, 17.04it/s]\u001b[A\r\n",
      "Validation DataLoader 0: 100%|████████████████| 119/119 [00:06<00:00, 17.06it/s]\u001b[A\r\n",
      "Epoch 0: 100%|███████████████████| 62236/62236 [27:16<00:00, 38.04it/s, v_num=0]\r\n",
      "2023/11/18 09:15:26 WARNING mlflow.utils.requirements_utils: Found jaxlib version (0.4.20+cuda11.cudnn86) contains a local version label (+cuda11.cudnn86). MLflow logged a pip requirement for this package as 'jaxlib==0.4.20' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\r\n",
      "2023/11/18 09:15:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\r\n",
      "Exported graph: graph(%item_indices : Long(*, strides=[1], requires_grad=0, device=cpu),\r\n",
      "      %k : Long(requires_grad=0, device=cpu),\r\n",
      "      %model.future_mask_const : Float(50, 50, strides=[50, 1], requires_grad=0, device=cpu),\r\n",
      "      %model.item_embedding.weight : Float(37484, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.positional_embedding_layer.pos_indices_const : Int(50, strides=[1], requires_grad=0, device=cpu),\r\n",
      "      %model.positional_embedding_layer.embedding.weight : Float(50, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.norm.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.norm.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.in_proj_weight : Float(600, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.in_proj_bias : Float(600, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.out_proj.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.out_proj.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear1.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear2.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear2.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm1.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm2.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm2.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.in_proj_weight : Float(600, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.in_proj_bias : Float(600, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.out_proj.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.out_proj.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear1.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear2.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear2.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm1.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm2.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm2.bias : Float(200, strides=[1], requires_grad=1, device=cpu)):\r\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "  %/Shape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%item_indices), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_1\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather\"](%/Shape_output_0, %/Constant_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %onnx::Unsqueeze_38 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze\"](%/Gather_output_0, %onnx::Unsqueeze_38), scope: src.sasrec.model.TopKModel::\r\n",
      "  %/Concat_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat\"](%/Unsqueeze_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/ConstantOfShape_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape\"](%/Concat_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_2\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Unsqueeze_1_output_0 : Float(1, *, strides=[15, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_1\"](%/ConstantOfShape_output_0, %/Constant_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_3\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Unsqueeze_2_output_0 : Long(1, *, strides=[15, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_2\"](%item_indices, %/Constant_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_4\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "  %/Shape_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_1\"](%/Unsqueeze_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:114:0\r\n",
      "  %/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_5\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:114:0\r\n",
      "  %/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_1\"](%/Shape_1_output_0, %/Constant_5_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:114:0\r\n",
      "  %/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_6\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_3\"](%/Constant_output_0, %/Constant_6_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_7\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_4\"](%/Gather_1_output_0, %/Constant_7_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_8\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_5\"](%/Constant_output_0, %/Constant_8_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_9\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Slice_output_0 : Float(*, *, strides=[50, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%model.future_mask_const, %/Unsqueeze_3_output_0, %/Unsqueeze_4_output_0, %/Unsqueeze_5_output_0, %/Constant_9_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_10\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_6\"](%/Constant_output_0, %/Constant_10_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_11\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_7\"](%/Gather_1_output_0, %/Constant_11_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_12\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_8\"](%/Constant_4_output_0, %/Constant_12_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_13\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/Slice_1_output_0 : Float(*, *, strides=[50, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_1\"](%/Slice_output_0, %/Unsqueeze_6_output_0, %/Unsqueeze_7_output_0, %/Unsqueeze_8_output_0, %/Constant_13_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:117:0\r\n",
      "  %/item_embedding/Gather_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name=\"/item_embedding/Gather\"](%model.item_embedding.weight, %/Unsqueeze_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.sparse.Embedding::item_embedding # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2194:0\r\n",
      "  %/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={14.1421}, onnx_name=\"/Constant_14\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:131:0\r\n",
      "  %/Mul_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/item_embedding/Gather_output_0, %/Constant_14_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:131:0\r\n",
      "  %/positional_embedding_layer/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/positional_embedding_layer/Shape\"](%/Mul_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:26:0\r\n",
      "  %/positional_embedding_layer/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/positional_embedding_layer/Constant\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:26:0\r\n",
      "  %/positional_embedding_layer/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/positional_embedding_layer/Gather\"](%/positional_embedding_layer/Shape_output_0, %/positional_embedding_layer/Constant_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:26:0\r\n",
      "  %/positional_embedding_layer/Neg_output_0 : Long(requires_grad=0, device=cpu) = onnx::Neg[onnx_name=\"/positional_embedding_layer/Neg\"](%/positional_embedding_layer/Gather_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/positional_embedding_layer/Constant_1\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer\r\n",
      "  %/positional_embedding_layer/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/positional_embedding_layer/Constant_2\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/positional_embedding_layer/Unsqueeze\"](%/positional_embedding_layer/Neg_output_0, %/positional_embedding_layer/Constant_2_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/positional_embedding_layer/Constant_3\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/positional_embedding_layer/Unsqueeze_1\"](%/positional_embedding_layer/Constant_1_output_0, %/positional_embedding_layer/Constant_3_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/positional_embedding_layer/Constant_4\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/positional_embedding_layer/Unsqueeze_2\"](%/Constant_output_0, %/positional_embedding_layer/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/positional_embedding_layer/Constant_5\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Slice_output_0 : Int(*, strides=[1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/positional_embedding_layer/Slice\"](%model.positional_embedding_layer.pos_indices_const, %/positional_embedding_layer/Unsqueeze_output_0, %/positional_embedding_layer/Unsqueeze_1_output_0, %/positional_embedding_layer/Unsqueeze_2_output_0, %/positional_embedding_layer/Constant_5_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/embedding/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/positional_embedding_layer/embedding/Constant\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer/torch.nn.modules.sparse.Embedding::embedding\r\n",
      "  %/positional_embedding_layer/embedding/Gather_output_0 : Float(*, 200, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name=\"/positional_embedding_layer/embedding/Gather\"](%model.positional_embedding_layer.embedding.weight, %/positional_embedding_layer/Slice_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer/torch.nn.modules.sparse.Embedding::embedding # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2194:0\r\n",
      "  %/positional_embedding_layer/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/positional_embedding_layer/Add\"](%/positional_embedding_layer/embedding/Gather_output_0, %/Mul_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/Session-Based-Models/src/sasrec/model.py:27:0\r\n",
      "  %/encoder/layers.0/norm1/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm1/ReduceMean\"](%/positional_embedding_layer/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.0/norm1/Sub\"](%/positional_embedding_layer/Add_output_0, %/encoder/layers.0/norm1/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/norm1/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.0/norm1/Pow\"](%/encoder/layers.0/norm1/Sub_output_0, %/encoder/layers.0/norm1/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm1/ReduceMean_1\"](%/encoder/layers.0/norm1/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.0/norm1/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm1/Add\"](%/encoder/layers.0/norm1/ReduceMean_1_output_0, %/encoder/layers.0/norm1/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.0/norm1/Sqrt\"](%/encoder/layers.0/norm1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/norm1/Div\"](%/encoder/layers.0/norm1/Sub_output_0, %/encoder/layers.0/norm1/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/norm1/Mul\"](%/encoder/layers.0/norm1/Div_output_0, %model.encoder.layers.0.norm1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm1/Add_1\"](%/encoder/layers.0/norm1/Mul_output_0, %model.encoder.layers.0.norm1.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_output_0 : Float(*, 1, 200, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose\"](%/encoder/layers.0/norm1/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1099:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape\"](%/encoder/layers.0/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather\"](%/encoder/layers.0/self_attn/Shape_output_0, %/encoder/layers.0/self_attn/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_1\"](%/encoder/layers.0/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_1\"](%/encoder/layers.0/self_attn/Shape_1_output_0, %/encoder/layers.0/self_attn/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_2\"](%/encoder/layers.0/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/self_attn/Constant_2\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_2\"](%/encoder/layers.0/self_attn/Shape_2_output_0, %/encoder/layers.0/self_attn/Constant_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_3\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/self_attn/Div\"](%/encoder/layers.0/self_attn/Gather_2_output_0, %/encoder/layers.0/self_attn/Constant_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.0/self_attn/Cast\"](%/encoder/layers.0/self_attn/Div_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.0/self_attn/Cast_1\"](%/encoder/layers.0/self_attn/Cast_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_1_output_0 : Float(200, 600, strides=[600, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.0/self_attn/Transpose_1\"](%model.encoder.layers.0.self_attn.in_proj_weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.0/self_attn/MatMul_output_0 : Float(*, 1, 600, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/self_attn/MatMul\"](%/encoder/layers.0/self_attn/Transpose_output_0, %/encoder/layers.0/self_attn/Transpose_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.0/self_attn/Add_output_0 : Float(*, 1, 600, strides=[600, 600, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/self_attn/Add\"](%model.encoder.layers.0.self_attn.in_proj_bias, %/encoder/layers.0/self_attn/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_3\"](%/encoder/layers.0/self_attn/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_4\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_3\"](%/encoder/layers.0/self_attn/Shape_3_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_5\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/self_attn/Constant_6\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/self_attn/Add_1\"](%/encoder/layers.0/self_attn/Gather_3_output_0, %/encoder/layers.0/self_attn/Constant_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.0/self_attn/Constant_7\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Div_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/self_attn/Div_1\"](%/encoder/layers.0/self_attn/Add_1_output_0, %/encoder/layers.0/self_attn/Constant_7_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_8\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul\"](%/encoder/layers.0/self_attn/Div_1_output_0, %/encoder/layers.0/self_attn/Constant_8_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Slice_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.0/self_attn/Slice\"](%/encoder/layers.0/self_attn/Add_output_0, %/encoder/layers.0/self_attn/Constant_5_output_0, %/encoder/layers.0/self_attn/Mul_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/self_attn/Constant_9\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_1\"](%/encoder/layers.0/self_attn/Div_1_output_0, %/encoder/layers.0/self_attn/Constant_9_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Slice_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.0/self_attn/Slice_1\"](%/encoder/layers.0/self_attn/Add_output_0, %/encoder/layers.0/self_attn/Mul_output_0, %/encoder/layers.0/self_attn/Mul_1_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.0/self_attn/Constant_10\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_2\"](%/encoder/layers.0/self_attn/Div_1_output_0, %/encoder/layers.0/self_attn/Constant_10_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Slice_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.0/self_attn/Slice_2\"](%/encoder/layers.0/self_attn/Add_output_0, %/encoder/layers.0/self_attn/Mul_1_output_0, %/encoder/layers.0/self_attn/Mul_2_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_11\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5037:0\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_output_0 : Float(1, *, *, strides=[750, 50, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze\"](%/Slice_1_output_0, %/encoder/layers.0/self_attn/Constant_11_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5037:0\r\n",
      "  %onnx::Unsqueeze_132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_1\"](%/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_132), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_2\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_134), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_3\"](%/encoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_136), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat\"](%/encoder/layers.0/self_attn/Unsqueeze_1_output_0, %/encoder/layers.0/self_attn/Unsqueeze_2_output_0, %/encoder/layers.0/self_attn/Unsqueeze_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape\"](%/encoder/layers.0/self_attn/Slice_output_0, %/encoder/layers.0/self_attn/Concat_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_2\"](%/encoder/layers.0/self_attn/Reshape_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_4\"](%/encoder/layers.0/self_attn/Slice_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_12\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_4\"](%/encoder/layers.0/self_attn/Shape_4_output_0, %/encoder/layers.0/self_attn/Constant_12_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %onnx::Unsqueeze_144 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_4\"](%/encoder/layers.0/self_attn/Gather_4_output_0, %onnx::Unsqueeze_144), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_5\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_146), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_148 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_6\"](%/encoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_148), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_1\"](%/encoder/layers.0/self_attn/Unsqueeze_4_output_0, %/encoder/layers.0/self_attn/Unsqueeze_5_output_0, %/encoder/layers.0/self_attn/Unsqueeze_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_1\"](%/encoder/layers.0/self_attn/Slice_1_output_0, %/encoder/layers.0/self_attn/Concat_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_5\"](%/encoder/layers.0/self_attn/Slice_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_13_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_13\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_5\"](%/encoder/layers.0/self_attn/Shape_5_output_0, %/encoder/layers.0/self_attn/Constant_13_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %onnx::Unsqueeze_155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_7\"](%/encoder/layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_155), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_8\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_157), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_9\"](%/encoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_159), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_2\"](%/encoder/layers.0/self_attn/Unsqueeze_7_output_0, %/encoder/layers.0/self_attn/Unsqueeze_8_output_0, %/encoder/layers.0/self_attn/Unsqueeze_9_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_2\"](%/encoder/layers.0/self_attn/Slice_2_output_0, %/encoder/layers.0/self_attn/Concat_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_3\"](%/encoder/layers.0/self_attn/Reshape_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={14.1421}, onnx_name=\"/encoder/layers.0/self_attn/Constant_14\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.0/self_attn/Div_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/self_attn/Div_2\"](%/encoder/layers.0/self_attn/Transpose_2_output_0, %/encoder/layers.0/self_attn/Constant_14_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[200, 1, 200], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 2, 0], onnx_name=\"/encoder/layers.0/self_attn/Transpose_4\"](%/encoder/layers.0/self_attn/Reshape_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/MatMul_1_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/self_attn/MatMul_1\"](%/encoder/layers.0/self_attn/Div_2_output_0, %/encoder/layers.0/self_attn/Transpose_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.0/self_attn/Cast_2\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_3\"](%/encoder/layers.0/self_attn/MatMul_1_output_0, %/encoder/layers.0/self_attn/Cast_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_3_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.0/self_attn/Cast_3\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_4_output_0 : Float(1, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_4\"](%/encoder/layers.0/self_attn/Unsqueeze_output_0, %/encoder/layers.0/self_attn/Cast_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Add_2_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/self_attn/Add_2\"](%/encoder/layers.0/self_attn/Mul_3_output_0, %/encoder/layers.0/self_attn/Mul_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Softmax_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/encoder/layers.0/self_attn/Softmax\"](%/encoder/layers.0/self_attn/Add_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1838:0\r\n",
      "  %/encoder/layers.0/self_attn/MatMul_2_output_0 : Float(*, *, *, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/self_attn/MatMul_2\"](%/encoder/layers.0/self_attn/Softmax_output_0, %/encoder/layers.0/self_attn/Transpose_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_5_output_0 : Float(*, *, *, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_5\"](%/encoder/layers.0/self_attn/MatMul_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_5\"](%/encoder/layers.0/self_attn/Gather_output_0, %/encoder/layers.0/self_attn/Gather_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %onnx::Unsqueeze_177 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_10\"](%/encoder/layers.0/self_attn/Mul_5_output_0, %onnx::Unsqueeze_177), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_11\"](%/encoder/layers.0/self_attn/Gather_2_output_0, %onnx::Unsqueeze_179), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_3\"](%/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/encoder/layers.0/self_attn/Unsqueeze_11_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_3_output_0 : Float(*, *, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_3\"](%/encoder/layers.0/self_attn/Transpose_5_output_0, %/encoder/layers.0/self_attn/Concat_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Gemm_output_0 : Float(*, 200, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/encoder/layers.0/self_attn/Gemm\"](%/encoder/layers.0/self_attn/Reshape_3_output_0, %model.encoder.layers.0.self_attn.out_proj.weight, %model.encoder.layers.0.self_attn.out_proj.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_6\"](%/encoder/layers.0/self_attn/Gemm_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_15\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_6\"](%/encoder/layers.0/self_attn/Shape_6_output_0, %/encoder/layers.0/self_attn/Constant_15_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %onnx::Unsqueeze_187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_12\"](%/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_187), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_13\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_189), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_14\"](%/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_191), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_4\"](%/encoder/layers.0/self_attn/Unsqueeze_12_output_0, %/encoder/layers.0/self_attn/Unsqueeze_13_output_0, %/encoder/layers.0/self_attn/Unsqueeze_14_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_4_output_0 : Float(*, 1, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_4\"](%/encoder/layers.0/self_attn/Gemm_output_0, %/encoder/layers.0/self_attn/Concat_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_6_output_0 : Float(1, *, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_6\"](%/encoder/layers.0/self_attn/Reshape_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1121:0\r\n",
      "  %/encoder/layers.0/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/Add\"](%/positional_embedding_layer/Add_output_0, %/encoder/layers.0/self_attn/Transpose_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:491:0\r\n",
      "  %/encoder/layers.0/norm2/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm2/ReduceMean\"](%/encoder/layers.0/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.0/norm2/Sub\"](%/encoder/layers.0/Add_output_0, %/encoder/layers.0/norm2/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/norm2/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.0/norm2/Pow\"](%/encoder/layers.0/norm2/Sub_output_0, %/encoder/layers.0/norm2/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm2/ReduceMean_1\"](%/encoder/layers.0/norm2/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.0/norm2/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm2/Add\"](%/encoder/layers.0/norm2/ReduceMean_1_output_0, %/encoder/layers.0/norm2/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.0/norm2/Sqrt\"](%/encoder/layers.0/norm2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/norm2/Div\"](%/encoder/layers.0/norm2/Sub_output_0, %/encoder/layers.0/norm2/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/norm2/Mul\"](%/encoder/layers.0/norm2/Div_output_0, %model.encoder.layers.0.norm2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm2/Add_1\"](%/encoder/layers.0/norm2/Mul_output_0, %model.encoder.layers.0.norm2.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/linear1/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.0/linear1/Transpose\"](%model.encoder.layers.0.linear1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear1/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/linear1/MatMul\"](%/encoder/layers.0/norm2/Add_1_output_0, %/encoder/layers.0/linear1/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear1/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/linear1/Add\"](%model.encoder.layers.0.linear1.bias, %/encoder/layers.0/linear1/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/Relu_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/layers.0/Relu\"](%/encoder/layers.0/linear1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\r\n",
      "  %/encoder/layers.0/linear2/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.0/linear2/Transpose\"](%model.encoder.layers.0.linear2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear2/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/linear2/MatMul\"](%/encoder/layers.0/Relu_output_0, %/encoder/layers.0/linear2/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear2/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/linear2/Add\"](%model.encoder.layers.0.linear2.bias, %/encoder/layers.0/linear2/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/Add_1\"](%/encoder/layers.0/Add_output_0, %/encoder/layers.0/linear2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:492:0\r\n",
      "  %/encoder/layers.1/norm1/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm1/ReduceMean\"](%/encoder/layers.0/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.1/norm1/Sub\"](%/encoder/layers.0/Add_1_output_0, %/encoder/layers.1/norm1/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/norm1/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.1/norm1/Pow\"](%/encoder/layers.1/norm1/Sub_output_0, %/encoder/layers.1/norm1/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm1/ReduceMean_1\"](%/encoder/layers.1/norm1/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.1/norm1/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm1/Add\"](%/encoder/layers.1/norm1/ReduceMean_1_output_0, %/encoder/layers.1/norm1/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.1/norm1/Sqrt\"](%/encoder/layers.1/norm1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/norm1/Div\"](%/encoder/layers.1/norm1/Sub_output_0, %/encoder/layers.1/norm1/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/norm1/Mul\"](%/encoder/layers.1/norm1/Div_output_0, %model.encoder.layers.1.norm1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm1/Add_1\"](%/encoder/layers.1/norm1/Mul_output_0, %model.encoder.layers.1.norm1.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_output_0 : Float(*, 1, 200, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose\"](%/encoder/layers.1/norm1/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1099:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape\"](%/encoder/layers.1/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather\"](%/encoder/layers.1/self_attn/Shape_output_0, %/encoder/layers.1/self_attn/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_1\"](%/encoder/layers.1/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_1\"](%/encoder/layers.1/self_attn/Shape_1_output_0, %/encoder/layers.1/self_attn/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_2\"](%/encoder/layers.1/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/self_attn/Constant_2\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_2\"](%/encoder/layers.1/self_attn/Shape_2_output_0, %/encoder/layers.1/self_attn/Constant_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_3\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/self_attn/Div\"](%/encoder/layers.1/self_attn/Gather_2_output_0, %/encoder/layers.1/self_attn/Constant_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.1/self_attn/Cast\"](%/encoder/layers.1/self_attn/Div_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.1/self_attn/Cast_1\"](%/encoder/layers.1/self_attn/Cast_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_1_output_0 : Float(200, 600, strides=[600, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.1/self_attn/Transpose_1\"](%model.encoder.layers.1.self_attn.in_proj_weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.1/self_attn/MatMul_output_0 : Float(*, 1, 600, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/self_attn/MatMul\"](%/encoder/layers.1/self_attn/Transpose_output_0, %/encoder/layers.1/self_attn/Transpose_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.1/self_attn/Add_output_0 : Float(*, 1, 600, strides=[600, 600, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/self_attn/Add\"](%model.encoder.layers.1.self_attn.in_proj_bias, %/encoder/layers.1/self_attn/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_3\"](%/encoder/layers.1/self_attn/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_4\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_3\"](%/encoder/layers.1/self_attn/Shape_3_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant_5\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/self_attn/Constant_6\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/self_attn/Add_1\"](%/encoder/layers.1/self_attn/Gather_3_output_0, %/encoder/layers.1/self_attn/Constant_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.1/self_attn/Constant_7\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Div_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/self_attn/Div_1\"](%/encoder/layers.1/self_attn/Add_1_output_0, %/encoder/layers.1/self_attn/Constant_7_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_8\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul\"](%/encoder/layers.1/self_attn/Div_1_output_0, %/encoder/layers.1/self_attn/Constant_8_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Slice_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.1/self_attn/Slice\"](%/encoder/layers.1/self_attn/Add_output_0, %/encoder/layers.1/self_attn/Constant_5_output_0, %/encoder/layers.1/self_attn/Mul_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/self_attn/Constant_9\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_1\"](%/encoder/layers.1/self_attn/Div_1_output_0, %/encoder/layers.1/self_attn/Constant_9_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Slice_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.1/self_attn/Slice_1\"](%/encoder/layers.1/self_attn/Add_output_0, %/encoder/layers.1/self_attn/Mul_output_0, %/encoder/layers.1/self_attn/Mul_1_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.1/self_attn/Constant_10\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_2\"](%/encoder/layers.1/self_attn/Div_1_output_0, %/encoder/layers.1/self_attn/Constant_10_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Slice_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.1/self_attn/Slice_2\"](%/encoder/layers.1/self_attn/Add_output_0, %/encoder/layers.1/self_attn/Mul_1_output_0, %/encoder/layers.1/self_attn/Mul_2_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %onnx::Unsqueeze_261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze\"](%/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_261), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_1\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_263), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_2\"](%/encoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_265), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat\"](%/encoder/layers.1/self_attn/Unsqueeze_output_0, %/encoder/layers.1/self_attn/Unsqueeze_1_output_0, %/encoder/layers.1/self_attn/Unsqueeze_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape\"](%/encoder/layers.1/self_attn/Slice_output_0, %/encoder/layers.1/self_attn/Concat_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_2\"](%/encoder/layers.1/self_attn/Reshape_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_4\"](%/encoder/layers.1/self_attn/Slice_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant_11\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_4\"](%/encoder/layers.1/self_attn/Shape_4_output_0, %/encoder/layers.1/self_attn/Constant_11_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %onnx::Unsqueeze_273 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_3\"](%/encoder/layers.1/self_attn/Gather_4_output_0, %onnx::Unsqueeze_273), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_275 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_4\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_275), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_277 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_5\"](%/encoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_277), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_1\"](%/encoder/layers.1/self_attn/Unsqueeze_3_output_0, %/encoder/layers.1/self_attn/Unsqueeze_4_output_0, %/encoder/layers.1/self_attn/Unsqueeze_5_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_1\"](%/encoder/layers.1/self_attn/Slice_1_output_0, %/encoder/layers.1/self_attn/Concat_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_5\"](%/encoder/layers.1/self_attn/Slice_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant_12\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_5\"](%/encoder/layers.1/self_attn/Shape_5_output_0, %/encoder/layers.1/self_attn/Constant_12_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %onnx::Unsqueeze_284 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_6\"](%/encoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_284), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_286 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_7\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_286), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_288 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_8\"](%/encoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_288), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_2\"](%/encoder/layers.1/self_attn/Unsqueeze_6_output_0, %/encoder/layers.1/self_attn/Unsqueeze_7_output_0, %/encoder/layers.1/self_attn/Unsqueeze_8_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_2\"](%/encoder/layers.1/self_attn/Slice_2_output_0, %/encoder/layers.1/self_attn/Concat_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_3\"](%/encoder/layers.1/self_attn/Reshape_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={14.1421}, onnx_name=\"/encoder/layers.1/self_attn/Constant_13\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.1/self_attn/Div_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/self_attn/Div_2\"](%/encoder/layers.1/self_attn/Transpose_2_output_0, %/encoder/layers.1/self_attn/Constant_13_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[200, 1, 200], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 2, 0], onnx_name=\"/encoder/layers.1/self_attn/Transpose_4\"](%/encoder/layers.1/self_attn/Reshape_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/MatMul_1_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/self_attn/MatMul_1\"](%/encoder/layers.1/self_attn/Div_2_output_0, %/encoder/layers.1/self_attn/Transpose_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.1/self_attn/Cast_2\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_3\"](%/encoder/layers.1/self_attn/MatMul_1_output_0, %/encoder/layers.1/self_attn/Cast_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_3_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.1/self_attn/Cast_3\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_4_output_0 : Float(1, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_4\"](%/encoder/layers.0/self_attn/Unsqueeze_output_0, %/encoder/layers.1/self_attn/Cast_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Add_2_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/self_attn/Add_2\"](%/encoder/layers.1/self_attn/Mul_3_output_0, %/encoder/layers.1/self_attn/Mul_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Softmax_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/encoder/layers.1/self_attn/Softmax\"](%/encoder/layers.1/self_attn/Add_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1838:0\r\n",
      "  %/encoder/layers.1/self_attn/MatMul_2_output_0 : Float(*, *, *, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/self_attn/MatMul_2\"](%/encoder/layers.1/self_attn/Softmax_output_0, %/encoder/layers.1/self_attn/Transpose_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_5_output_0 : Float(*, *, *, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_5\"](%/encoder/layers.1/self_attn/MatMul_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_5\"](%/encoder/layers.1/self_attn/Gather_output_0, %/encoder/layers.1/self_attn/Gather_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %onnx::Unsqueeze_306 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_9\"](%/encoder/layers.1/self_attn/Mul_5_output_0, %onnx::Unsqueeze_306), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_10\"](%/encoder/layers.1/self_attn/Gather_2_output_0, %onnx::Unsqueeze_308), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_3\"](%/encoder/layers.1/self_attn/Unsqueeze_9_output_0, %/encoder/layers.1/self_attn/Unsqueeze_10_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_3_output_0 : Float(*, *, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_3\"](%/encoder/layers.1/self_attn/Transpose_5_output_0, %/encoder/layers.1/self_attn/Concat_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Gemm_output_0 : Float(*, 200, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/encoder/layers.1/self_attn/Gemm\"](%/encoder/layers.1/self_attn/Reshape_3_output_0, %model.encoder.layers.1.self_attn.out_proj.weight, %model.encoder.layers.1.self_attn.out_proj.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_6\"](%/encoder/layers.1/self_attn/Gemm_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_14\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_6\"](%/encoder/layers.1/self_attn/Shape_6_output_0, %/encoder/layers.1/self_attn/Constant_14_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %onnx::Unsqueeze_316 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_11\"](%/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_316), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_12\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_318), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_13\"](%/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_320), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_4\"](%/encoder/layers.1/self_attn/Unsqueeze_11_output_0, %/encoder/layers.1/self_attn/Unsqueeze_12_output_0, %/encoder/layers.1/self_attn/Unsqueeze_13_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_4_output_0 : Float(*, 1, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_4\"](%/encoder/layers.1/self_attn/Gemm_output_0, %/encoder/layers.1/self_attn/Concat_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_6_output_0 : Float(1, *, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_6\"](%/encoder/layers.1/self_attn/Reshape_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1121:0\r\n",
      "  %/encoder/layers.1/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/Add\"](%/encoder/layers.0/Add_1_output_0, %/encoder/layers.1/self_attn/Transpose_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:491:0\r\n",
      "  %/encoder/layers.1/norm2/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm2/ReduceMean\"](%/encoder/layers.1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.1/norm2/Sub\"](%/encoder/layers.1/Add_output_0, %/encoder/layers.1/norm2/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/norm2/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.1/norm2/Pow\"](%/encoder/layers.1/norm2/Sub_output_0, %/encoder/layers.1/norm2/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm2/ReduceMean_1\"](%/encoder/layers.1/norm2/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.1/norm2/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm2/Add\"](%/encoder/layers.1/norm2/ReduceMean_1_output_0, %/encoder/layers.1/norm2/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.1/norm2/Sqrt\"](%/encoder/layers.1/norm2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/norm2/Div\"](%/encoder/layers.1/norm2/Sub_output_0, %/encoder/layers.1/norm2/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/norm2/Mul\"](%/encoder/layers.1/norm2/Div_output_0, %model.encoder.layers.1.norm2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm2/Add_1\"](%/encoder/layers.1/norm2/Mul_output_0, %model.encoder.layers.1.norm2.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/linear1/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.1/linear1/Transpose\"](%model.encoder.layers.1.linear1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear1/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/linear1/MatMul\"](%/encoder/layers.1/norm2/Add_1_output_0, %/encoder/layers.1/linear1/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear1/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/linear1/Add\"](%model.encoder.layers.1.linear1.bias, %/encoder/layers.1/linear1/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/Relu_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/layers.1/Relu\"](%/encoder/layers.1/linear1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1 # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\r\n",
      "  %/encoder/layers.1/linear2/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.1/linear2/Transpose\"](%model.encoder.layers.1.linear2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear2/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/linear2/MatMul\"](%/encoder/layers.1/Relu_output_0, %/encoder/layers.1/linear2/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear2/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/linear2/Add\"](%model.encoder.layers.1.linear2.bias, %/encoder/layers.1/linear2/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/Add_1\"](%/encoder/layers.1/Add_output_0, %/encoder/layers.1/linear2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1 # /opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:492:0\r\n",
      "  %/encoder/norm/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/norm/ReduceMean\"](%/encoder/layers.1/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/norm/Sub\"](%/encoder/layers.1/Add_1_output_0, %/encoder/norm/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/norm/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/norm/Pow\"](%/encoder/norm/Sub_output_0, %/encoder/norm/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/norm/ReduceMean_1\"](%/encoder/norm/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/norm/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/norm/Add\"](%/encoder/norm/ReduceMean_1_output_0, %/encoder/norm/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/norm/Sqrt\"](%/encoder/norm/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/norm/Div\"](%/encoder/norm/Sub_output_0, %/encoder/norm/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/norm/Mul\"](%/encoder/norm/Div_output_0, %model.norm.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/norm/Add_1\"](%/encoder/norm/Mul_output_0, %model.norm.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/Gather_2_output_0 : Float(1, 200, strides=[3000, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name=\"/Gather_2\"](%/encoder/norm/Add_1_output_0, %/positional_embedding_layer/embedding/Constant_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:185:0\r\n",
      "  %/Transpose_output_0 : Float(200, 37484, strides=[1, 200], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/Transpose\"](%model.item_embedding.weight), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/shared/logits_computation.py:5:0\r\n",
      "  %/MatMul_output_0 : Float(1, 37484, strides=[37484, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul\"](%/Gather_2_output_0, %/Transpose_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/shared/logits_computation.py:5:0\r\n",
      "  %/Gather_3_output_0 : Float(37484, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_3\"](%/MatMul_output_0, %/Constant_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Gather_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_4\"](%/Gather_3_output_0, %/Constant_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name=\"/Constant_15\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_2\"](%/Gather_4_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_output_0 : Float(requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand\"](%/Constant_15_output_0, %/Shape_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_16\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_17_output_0 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_17\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_18_output_0 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_18\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_19\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Add_output_0 : Long(1, 1, strides=[1, 1], device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Constant_18_output_0, %/Constant_19_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_3\"](%/Add_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_4\"](%/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/ConstantOfShape_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_1\"](%/Shape_4_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_20_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_20\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Mul_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/ConstantOfShape_1_output_0, %/Constant_20_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal\"](%/Shape_3_output_0, %/Mul_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Where_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where\"](%/Equal_output_0, %/ConstantOfShape_1_output_0, %/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_1_output_0 : Long(1, 1, strides=[1, 1], device=cpu) = onnx::Expand[onnx_name=\"/Expand_1\"](%/Constant_17_output_0, %/Where_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_21\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Unsqueeze_9_output_0 : Long(1, 1, 1, strides=[1, 1, 1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_9\"](%/Expand_1_output_0, %/Constant_21_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_5\"](%/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/ConstantOfShape_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_2\"](%/Shape_5_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_22_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_22\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Mul_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_2\"](%/ConstantOfShape_2_output_0, %/Constant_22_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_1_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_1\"](%/Shape_3_output_0, %/Mul_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Where_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_1\"](%/Equal_1_output_0, %/ConstantOfShape_2_output_0, %/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_2_output_0 : Long(1, 1, strides=[1, 1], device=cpu) = onnx::Expand[onnx_name=\"/Expand_2\"](%/Constant_16_output_0, %/Where_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_23\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Unsqueeze_10_output_0 : Long(1, 1, 1, strides=[1, 1, 1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_10\"](%/Expand_2_output_0, %/Constant_23_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Concat_1_output_0 : Long(1, 1, 2, strides=[2, 2, 1], device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_1\"](%/Unsqueeze_9_output_0, %/Unsqueeze_10_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_6\"](%/MatMul_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_24\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_25\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_26\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Slice_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice_2\"](%/Shape_6_output_0, %/Constant_25_output_0, %/Constant_26_output_0, %/Constant_24_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Concat_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_2\"](%/Shape_3_output_0, %/Slice_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_7\"](%/Concat_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/ConstantOfShape_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_3\"](%/Shape_7_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_27\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Mul_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_3\"](%/ConstantOfShape_3_output_0, %/Constant_27_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_2_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_2\"](%/Concat_2_output_0, %/Mul_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Where_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_2\"](%/Equal_2_output_0, %/ConstantOfShape_3_output_0, %/Concat_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_3_output_0 : Float(1, 1, strides=[1, 1], device=cpu) = onnx::Expand[onnx_name=\"/Expand_3\"](%/Expand_output_0, %/Where_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Reshape_output_0 : Float(1, 1, strides=[1, 1], device=cpu) = onnx::Reshape[onnx_name=\"/Reshape\"](%/Expand_3_output_0, %/Concat_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/ScatterND_output_0 : Float(1, 37484, requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name=\"/ScatterND\"](%/MatMul_output_0, %/Concat_1_output_0, %/Reshape_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_28\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_1\"](%k, %/Constant_28_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/TopK_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu), %/TopK_output_1 : Long(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::TopK[axis=-1, largest=1, sorted=1, onnx_name=\"/TopK\"](%/ScatterND_output_0, %/Reshape_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_29\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_8\"](%/TopK_output_1), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Gather_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_5\"](%/Shape_8_output_0, %/Constant_29_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_30\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_3_output_0 : Bool(1, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_3\"](%/Gather_5_output_0, %/Constant_30_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "  %indices : Long(*, device=cpu) = onnx::If[onnx_name=\"/If\"](%/Equal_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:186:0\r\n",
      "    block0():\r\n",
      "      %/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_31\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "      %/Squeeze_output_0 : Long(*, device=cpu) = onnx::Squeeze[onnx_name=\"/Squeeze\"](%/TopK_output_1, %/Constant_31_output_0), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Squeeze_output_0)\r\n",
      "    block1():\r\n",
      "      %/Identity_output_0 : Long(*, *, device=cpu) = onnx::Identity[onnx_name=\"/Identity\"](%/TopK_output_1), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Identity_output_0)\r\n",
      "  %/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_32\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:187:0\r\n",
      "  %/Shape_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_9\"](%/TopK_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:187:0\r\n",
      "  %/Gather_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_6\"](%/Shape_9_output_0, %/Constant_32_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:187:0\r\n",
      "  %/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_33\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:187:0\r\n",
      "  %/Equal_4_output_0 : Bool(1, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_4\"](%/Gather_6_output_0, %/Constant_33_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:187:0\r\n",
      "  %scores : Float(*, device=cpu) = onnx::If[onnx_name=\"/If_1\"](%/Equal_4_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/Session-Based-Models/src/sasrec/model.py:187:0\r\n",
      "    block0():\r\n",
      "      %/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_34\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "      %/Squeeze_1_output_0 : Float(*, device=cpu) = onnx::Squeeze[onnx_name=\"/Squeeze_1\"](%/TopK_output_0, %/Constant_34_output_0), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Squeeze_1_output_0)\r\n",
      "    block1():\r\n",
      "      %/Identity_1_output_0 : Float(*, *, device=cpu) = onnx::Identity[onnx_name=\"/Identity_1\"](%/TopK_output_0), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Identity_1_output_0)\r\n",
      "  return (%indices, %scores)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python -m src --config_filename sasrec/sasrec_yoochoose_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91374273",
   "metadata": {
    "papermill": {
     "duration": 3.387421,
     "end_time": "2023-11-18T09:15:36.711702",
     "exception": false,
     "start_time": "2023-11-18T09:15:33.324281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3942929,
     "sourceId": 6860644,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2779.392139,
   "end_time": "2023-11-18T09:15:40.393713",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-18T08:29:21.001574",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
